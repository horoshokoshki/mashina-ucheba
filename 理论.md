# 理论基础
## 监督学习与无监督学习的区别
 *对于有标签（有y）的数据，我们进行有监督学习，常见的分类任务就是监督学习；
 *而对于无标签（无y）的数据，我们希望发现无标签的数据中的潜在信息，这就是无监督学习

## 损失函数（LOST）
是定义在单个训练样本上的，也就是就算一个样本的误差
*0-1损失函数
平方损失函数
绝对损失函数
对数损失函数

## 代价函数（COST）
定义在整个训练集上面的，也就是所有样本的误差的总和的平均，也就是损失函数的总和的平均，

# 监督学习方法

## k—NN
在训练数据集中找到最靠近实例的k个值
输入：训练数据集
输出：划分实例的所属的y

### 距离度量
Lp距离
欧式距离
minkowiski距离

### k值选择
k值过大会使模型过于简单，过小容易敏感而产生过拟合
因此会选择比较小的一个值

### kd树的构建
对于多实例的情况需要构建kd树

相当于不断在xy方向将空间划分
